"""
ç›‘æ§ä¸»ç¨‹åº
"""
import json
import os
from datetime import datetime
from typing import Dict, List
from scraper import fetch_games
from config import URLS, DATA_FILE


def load_data() -> Dict:
    """åŠ è½½å†å²æ•°æ®"""
    if os.path.exists(DATA_FILE):
        try:
            with open(DATA_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            pass
    return {}


def save_data(data: Dict):
    """ä¿å­˜æ•°æ®"""
    with open(DATA_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def find_new_games(old_games: List[Dict], new_games: List[Dict]) -> List[Dict]:
    """æŸ¥æ‰¾æ–°å¢æ¸¸æˆ"""
    old_urls = {game['url'] for game in old_games}
    return [game for game in new_games if game['url'] not in old_urls]


def create_issue_body(results: List[Dict]) -> str:
    """åˆ›å»º GitHub Issue å†…å®¹"""
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    body = f"## ğŸ® æ–°æ¸¸æˆæ£€æµ‹æŠ¥å‘Š\n\n"
    body += f"**æ£€æµ‹æ—¶é—´**: {timestamp}\n\n"
    
    total_new = sum(len(r['new_games']) for r in results)
    
    if total_new == 0:
        body += "### âœ… æœ¬æ¬¡æ£€æµ‹æœªå‘ç°æ–°æ¸¸æˆ\n\n"
    else:
        body += f"### ğŸ‰ å‘ç° {total_new} ä¸ªæ–°æ¸¸æˆï¼\n\n"
    
    for result in results:
        body += f"### ğŸ“‚ {result['display_name']}\n\n"
        body += f"- **æ€»æ¸¸æˆæ•°**: {result['total_games']}\n"
        body += f"- **æ–°å¢æ¸¸æˆ**: {len(result['new_games'])}\n\n"
        
        if result['new_games']:
            body += "**æ–°æ¸¸æˆåˆ—è¡¨**:\n\n"
            for i, game in enumerate(result['new_games'], 1):
                body += f"{i}. [{game['name']}]({game['url']})\n"
            body += "\n"
        else:
            body += "*æ— æ–°å¢æ¸¸æˆ*\n\n"
    
    body += "---\n"
    body += "*æ­¤æŠ¥å‘Šç”± GitHub Actions è‡ªåŠ¨ç”Ÿæˆ*\n"
    
    return body


def main():
    """ä¸»å‡½æ•°"""
    print("="*70)
    print("ğŸ” AZGames ç›‘æ§ç³»ç»Ÿ")
    print("="*70)
    
    # åŠ è½½å†å²æ•°æ®
    data = load_data()
    results = []
    has_new_games = False
    
    # æ£€æŸ¥æ¯ä¸ªURL
    for url_config in URLS:
        category = url_config['name']
        url = url_config['url']
        display_name = url_config['display_name']
        
        print(f"\næ­£åœ¨æ£€æŸ¥: {display_name}")
        
        # æŠ“å–å½“å‰æ¸¸æˆ
        current_games = fetch_games(url)
        
        if not current_games:
            print(f"âš ï¸  æœªèƒ½æŠ“å–åˆ°æ•°æ®")
            continue
        
        print(f"âœ“ æŠ“å–åˆ° {len(current_games)} ä¸ªæ¸¸æˆ")
        
        # è·å–å†å²æ•°æ®
        old_games = data.get(category, [])
        
        # æŸ¥æ‰¾æ–°æ¸¸æˆ
        new_games = find_new_games(old_games, current_games)
        
        if new_games:
            print(f"ğŸ® å‘ç° {len(new_games)} ä¸ªæ–°æ¸¸æˆï¼")
            has_new_games = True
            for game in new_games:
                print(f"  - {game['name']}")
        else:
            print(f"âœ“ æ— æ–°å¢æ¸¸æˆ")
        
        # æ›´æ–°æ•°æ®
        data[category] = current_games
        
        # è®°å½•ç»“æœ
        results.append({
            'category': category,
            'display_name': display_name,
            'total_games': len(current_games),
            'new_games': new_games
        })
    
    # ä¿å­˜æ•°æ®
    save_data(data)
    
    # ç”ŸæˆæŠ¥å‘Š
    report = create_issue_body(results)
    
    # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
    with open('report.md', 'w', encoding='utf-8') as f:
        f.write(report)
    
    # ä¿å­˜çŠ¶æ€ï¼ˆç”¨äº GitHub Actionsï¼‰
    with open('has_new_games.txt', 'w') as f:
        f.write('true' if has_new_games else 'false')
    
    print("\n" + "="*70)
    print(f"ğŸ“Š æ£€æŸ¥å®Œæˆ")
    print(f"  - æ£€æŸ¥äº† {len(results)} ä¸ªåˆ†ç±»")
    total_new = sum(len(r['new_games']) for r in results)
    print(f"  - å‘ç° {total_new} ä¸ªæ–°æ¸¸æˆ")
    print("="*70)
    
    return has_new_games


if __name__ == '__main__':
    main()
